A ResNet-18 based CNN model.
The ResNet-18 is a pretrained CNN model for capturing the spatial features of frames. Here, a video is taken as input, and then mediapipe is used to extract the frames from the video. The average length of videos is 10-20 seconds, and here, 100 frames are extracted per video. the extra information of the frame ( ex, background, body of the person is cropped out in order to save the memory wastage, as we are only focusing on the face for feature extraction. The frames are then fed to the CNN model, which extracts the spatial features from faces.

 The dataset name is FaceForensics++. It has 1000 real videos from YouTube and 4 different types of deepfake videos: face swap based, face2face, Neural Textured, and Deepfake using auto-encoders, each with 1000 manipulated videos according to the techniques used.
